# ğŸš€ GuÃ­a RÃ¡pida - Pipeline de Datos

## Resumen del Flujo de Trabajo

```
1. market_scraper.py  â†’  data/raw/market/*.parquet
                         â†“
2. run_pipeline.py    â†’  procesa raw + calcula indicadores
                         â†“
3. Resultado Final    â†’  data/processed/training_dataset.parquet
```

---

## ğŸ“‹ Pasos para Generar el Dataset

### Paso 1: Instalar Dependencias

```bash
cd sol-trader
pip install -r requirements.txt
```

### Paso 2: Descargar Datos de Mercado (Solo primera vez)

Si no tienes datos raw, descÃ¡rgalos:

```bash
python src/scrapers/market_scraper.py
```

Esto descargarÃ¡ ~6 meses de datos histÃ³ricos de SOL/USDT en intervalos de 15 minutos.

### Paso 3: Ejecutar el Pipeline Completo

```bash
python run_pipeline.py
```

**Â¿QuÃ© hace este script?**
1. âœ… Lee el archivo raw mÃ¡s reciente de `data/raw/market/`
2. âœ… Calcula indicadores tÃ©cnicos (RSI, ATR, EMA, Bollinger Bands)
3. âœ… Guarda datos procesados en `data/processed/SOL_USDT_15m_indicators.parquet`
4. âœ… Genera targets con umbral ATR dinÃ¡mico
5. âœ… Guarda dataset final en `data/processed/training_dataset.parquet`

### Paso 4: Analizar el Dataset Generado

```bash
python analyze_dataset.py
```

Esto mostrarÃ¡:
- DistribuciÃ³n de clases (Buy Signals vs No Trade)
- EstadÃ­sticas de precios y volatilidad
- Retornos esperados por clase
- Recomendaciones para ajustar parÃ¡metros

---

## ğŸ“Š Resultados Esperados

### Archivos Generados

```
sol-trader/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/market/
â”‚   â”‚   â””â”€â”€ SOL_USDT_15m_*.parquet         # Datos crudos de CCXT
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ SOL_USDT_15m_indicators.parquet # Con indicadores tÃ©cnicos
â”‚       â””â”€â”€ training_dataset.parquet        # Dataset etiquetado (FINAL)
```

### DistribuciÃ³n TÃ­pica de Clases

Con `atr_multiplier=1.5` (configuraciÃ³n por defecto):

| Clase | Porcentaje | DescripciÃ³n |
|-------|-----------|-------------|
| **0** (No Trade) | ~85-90% | Precio no se moverÃ¡ significativamente |
| **1** (Buy Signal) | ~10-15% | Precio subirÃ¡ mÃ¡s que el umbral ATR |

---

## âš™ï¸ Ajustando ParÃ¡metros

### Si hay POCOS Buy Signals (<10%)

Edita `run_pipeline.py` lÃ­nea 102:

```python
builder = DatasetBuilder(
    lookahead_candles=4,
    atr_multiplier=1.2  # Era 1.5, ahora mÃ¡s agresivo
)
```

### Si hay MUCHOS Buy Signals (>40%)

```python
builder = DatasetBuilder(
    lookahead_candles=4,
    atr_multiplier=2.0  # Era 1.5, ahora mÃ¡s conservador
)
```

DespuÃ©s de cambiar, vuelve a ejecutar:
```bash
python run_pipeline.py
```

---

## ğŸ”§ ConfiguraciÃ³n del .env (Opcional)

Para sentiment scraping necesitas una API key de CryptoPanic:

```bash
# Copia el ejemplo
cp .env.example .env

# Edita y aÃ±ade tu API key
nano .env
```

```env
CRYPTOPANIC_API_KEY=tu_api_key_aqui
```

---

## ğŸ“š Archivos Importantes

| Archivo | DescripciÃ³n |
|---------|-------------|
| `run_pipeline.py` | **Script principal** - Ejecuta todo el flujo |
| `analyze_dataset.py` | Analiza el dataset generado |
| `src/scrapers/market_scraper.py` | Descarga datos de Binance |
| `src/processors/technical_indicators.py` | Calcula RSI, ATR, EMA, BB |
| `src/quant_engine/dataset_builder.py` | Genera targets con ATR |

---

## ğŸ¯ PrÃ³ximos Pasos

Una vez tengas `training_dataset.parquet`:

1. **Dividir en train/val/test:**
   ```python
   import polars as pl

   df = pl.read_parquet("data/processed/training_dataset.parquet")

   # DivisiÃ³n temporal (80/10/10)
   n = len(df)
   train = df[:int(n*0.8)]
   val = df[int(n*0.8):int(n*0.9)]
   test = df[int(n*0.9):]
   ```

2. **Entrenar modelo Transformer** (prÃ³xima fase)

3. **Backtesting y evaluaciÃ³n**

---

## ğŸ› Troubleshooting

### Error: "No module named 'polars'"
```bash
pip install polars numpy ccxt requests python-dotenv
```

### Error: "No hay datos raw"
```bash
python src/scrapers/market_scraper.py
```

### Error: "Missing required columns"
AsegÃºrate de que el archivo raw tenga las columnas: `timestamp, open, high, low, close, volume`

---

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### Ejemplo de Salida del Pipeline:

```
ğŸ¯ Class Distribution:
   Total Samples:       7,261
   Buy Signals (1):     746 (10.27%)    â† Â¡Balanceado!
   No Trade (0):        6,515 (89.73%)

ğŸ“ˆ Performance Metrics:
   Avg Return (Buy):    1.232%    â† SeÃ±ales positivas
   Avg Return (No):     -0.160%   â† No trade = sin ganancia
```

**InterpretaciÃ³n:**
- âœ… **10.27% Buy Signals**: Balanceado, no hay overfitting
- âœ… **+1.232% Avg Return**: Las seÃ±ales de compra son rentables en promedio
- âœ… **-0.160% No Trade**: Correctamente identifica momentos sin movimiento

---

## ğŸš€ Comando Todo-en-Uno

```bash
# Instalar, descargar datos y procesar (primera vez)
pip install -r requirements.txt && \
python src/scrapers/market_scraper.py && \
python run_pipeline.py && \
python analyze_dataset.py
```

---

## ğŸ“ Soporte

Si encuentras problemas:
1. Verifica que todos los paquetes estÃ©n instalados
2. AsegÃºrate de tener datos raw descargados
3. Revisa los logs para errores especÃ­ficos
4. Consulta `docs/LABELING_STRATEGY.md` para detalles tÃ©cnicos
